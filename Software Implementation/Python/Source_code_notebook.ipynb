{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIE-PInCS project: python implementation\n",
    "## Firts implementation of video analysis for pupil tracking for identification and evaluation of Traumatic Brain Injury "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing phase:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for eye cascade function end eye classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc_fct = 1.3              \n",
    "min_neigh = 5             \n",
    "min_eye = (10, 10)\n",
    "max_eye = (50, 50)\n",
    "eyes = []\n",
    "eyeCascade=cv2.CascadeClassifier(\"./Assets/haarcascade_eye.xml\")\n",
    "dist_TH = 10\n",
    "res_fac = 4\n",
    "bound = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables containing data about pupils and eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CENTERS_RIGHTS = [(0,0)]\n",
    "DIAMS_RIGHTS = [0]\n",
    "CENTERS_LEFTS = [(0,0)]\n",
    "DIAMS_LEFTS = [0]\n",
    "r_check = []\n",
    "l_check = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters about source file to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_file = \"./Assets/light_stimulation.mp4\"\n",
    "#video_file = \"./Assets/dinamic_stimulation.mp4\"\n",
    "video_capture = cv2.VideoCapture(video_file)\n",
    "video_width = int(video_capture.get(3)) \n",
    "video_height = int(video_capture.get(4))\n",
    "frps = int(video_capture.get(5))\n",
    "frames = int(video_capture.get(7))\n",
    "Tc = 1/frps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for image analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pup_TH = 30\n",
    "windowClose = np.ones((5,5),np.uint8)\n",
    "windowOpen = np.ones((2,2),np.uint8)\n",
    "windowErode = np.ones((2,2),np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backgroung image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bground = cv2.imread('./Assets/Background.png')\n",
    "bgH,bgW, _ = bground.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'jpeg')\n",
    "out = cv2.VideoWriter('output.mp4',fourcc, frps, (bgW, bgH), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion factor from pixel to mm and unit of measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = 160/268 #from pixel to mm\n",
    "uom = 'mm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factors to write on the image output text and other images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1 = int(bgH/2 + 20)\n",
    "h_line = h1 + 30\n",
    "h2 = h1 + 80\n",
    "h3 = h2 + 30\n",
    "h4 = h3 + 30\n",
    "h5 = h4 + 50\n",
    "center = int(bgW/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function puts an image on other, starting from a point (i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw(img1, img2, i, j):          # i = vertical, j = horizontal\n",
    "    h,w, _ = img2.shape\n",
    "    img1[i:i+h, j:j+w] = img2[:h, :w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function makes an image totally black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rubber(img):\n",
    "    h,w, _ = img.shape\n",
    "    img[:h, :w] = (0,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function writes, on a predetermined point, factors taken in input: value of scale, diameters and time on output image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_img(image, count, diam_r, diam_l, scl):\n",
    "    cv2.putText(image, text='SCALE: '+str(scl)+uom, org=(center-70, h1), fontFace=2, fontScale=0.6, color=(255,255,255), thickness=1)\n",
    "    cv2.putText(image, text='DIAMETERS:', org=(center-70, h2), fontFace=2, fontScale=0.6, color=(255,255,255), thickness=1)\n",
    "    cv2.putText(image, text='right: '+str(round(diam_r,1))+uom, org=(center-70, h3), fontFace=2, fontScale=0.6, color=(255,255,255), thickness=1)\n",
    "    cv2.putText(image, text='left: '+str(round(diam_l,1))+uom, org=(center-70, h4), fontFace=2, fontScale=0.6, color=(255,255,255), thickness=1)\n",
    "    t = count*Tc*1000\n",
    "    cv2.putText(image, text='time: '+str(int(t))+'ms', org=(center-70, h5), fontFace=2, fontScale=0.6, color=(255,255,255), thickness=1)\n",
    "    # comparing line \n",
    "    shift = int((0.5*scl*res_fac)/K)\n",
    "    cv2.line(image, (center-shift,h_line), (center+shift,h_line), color=(255,255,255), thickness=2) \n",
    "    cv2.line(image, (center-shift,h_line+10), (center-shift,h_line-10), color=(255,255,255), thickness=2)\n",
    "    cv2.line(image, (center+shift,h_line+10), (center+shift,h_line-10), color=(255,255,255), thickness=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function classifies eyes in rights and lefts; classification is based on position of ROI within the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_eyes(eyes, rx0, ry0, lx0, ly0):\n",
    "    r = []\n",
    "    l = []\n",
    "    for (x,y,w,h) in eyes:\n",
    "        if x > video_width*0.5 and (abs(x-rx0) < dist_TH and abs(y-ry0) < dist_TH):\n",
    "            r.append((x,y,w,h))\n",
    "        elif x < video_width*0.5 and (abs(x-lx0) < dist_TH and abs(y-ly0) < dist_TH):\n",
    "            l.append((x,y,w,h))\n",
    "    return r,l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function return values of the correct eye among a vector; it choises the closest eye from an established point of previous eye position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_eye(eye_list, point):    \n",
    "    eyes = []\n",
    "    min_dist = video_width\n",
    "    \n",
    "    for (x,y,w,h) in eye_list:            \n",
    "        distance = abs(x-point)\n",
    "        if (distance < min_dist):\n",
    "            ex = x\n",
    "            ey = y\n",
    "            ew = w\n",
    "            eh = h\n",
    "            min_dist = distance\n",
    "            \n",
    "    return ex,ey,ew,eh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function takes in input a ROI containing eye and return, if it is possible, center position and diameter of finded pupil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findpupil(roi, x, y, w):\n",
    "    max_rad = w/3\n",
    "    min_rad = w/10\n",
    "    \n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_RGB2GRAY)\n",
    "    pupilFrame = cv2.equalizeHist(roi)\n",
    "    pupilO = pupilFrame\n",
    "    ret, pupilFrame = cv2.threshold(pupilFrame,pup_TH,255,cv2.THRESH_BINARY)\n",
    "    pupilFrame = cv2.morphologyEx(pupilFrame, cv2.MORPH_CLOSE, windowClose)\n",
    "    pupilFrame = cv2.morphologyEx(pupilFrame, cv2.MORPH_ERODE, windowErode)\n",
    "    pupilFrame = cv2.morphologyEx(pupilFrame, cv2.MORPH_OPEN, windowOpen)\n",
    "    \n",
    "    threshold = cv2.inRange(pupilFrame,250,255)\n",
    "    _, contours, hierarchy = cv2.findContours(threshold,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) >= 2:\n",
    "        maxArea = 0\n",
    "        MAindex = 0\n",
    "        distanceX = []\n",
    "        currentIndex = 0 \n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            center = cv2.moments(cnt)\n",
    "            if center['m00'] != 0:\n",
    "                cx,cy = int(center['m10']/center['m00']), int(center['m01']/center['m00'])\n",
    "                distanceX.append(cx)\n",
    "                if area > maxArea:\n",
    "                    maxArea = area\n",
    "                    MAindex = currentIndex\n",
    "                currentIndex += 1\n",
    "        \n",
    "        del contours[MAindex]\n",
    "        del distanceX[MAindex]\n",
    "\n",
    "        eye = 'right'\n",
    "\n",
    "        if len(contours) >= 2:\n",
    "            if eye == 'right':\n",
    "                edgeOfEye = distanceX.index(min(distanceX))\n",
    "            else:\n",
    "                edgeOfEye = distanceX.index(max(distanceX))\n",
    "            del contours[edgeOfEye]\n",
    "            del distanceX[edgeOfEye]\n",
    "\n",
    "        if len(contours) >= 1:\n",
    "            maxArea = 0\n",
    "            for cnt in contours:\n",
    "                area = cv2.contourArea(cnt)\n",
    "                if area > maxArea:\n",
    "                    maxArea = area\n",
    "                    largeBlob = cnt\n",
    "\n",
    "        if len(largeBlob) > 0:\n",
    "            center = cv2.moments(largeBlob)\n",
    "            if center['m00'] != 0:\n",
    "                cx,cy = int(center['m10']/center['m00']), int(center['m01']/center['m00'])\n",
    "                rad = (center['m00'] / math.pi)**0.5\n",
    "                if rad < max_rad and rad > min_rad:\n",
    "                    return ((int(cx+x), int(cy+y)), rad)\n",
    "            else:\n",
    "                return None, None\n",
    "        \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code of kernel:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first algorithm search the first frame containing exactly two eyes, and then classifies them in left and right, assigning the values of initial eye position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while len(eyes) != 2:\n",
    "    ret, frame = video_capture.read()\n",
    "    eyes=eyeCascade.detectMultiScale(frame, scaleFactor=sc_fct, minNeighbors=min_neigh, minSize=min_eye, maxSize=max_eye)\n",
    "    \n",
    "if eyes[0][0] > eyes[1][0]:\n",
    "    \n",
    "    x0r = eyes [0][0]\n",
    "    y0r = eyes [0][1]\n",
    "    w0r = eyes [0][2]\n",
    "    h0r = eyes [0][3]\n",
    "    \n",
    "    x0l = eyes [1][0]\n",
    "    y0l = eyes [1][1]\n",
    "    w0l = eyes [1][2]\n",
    "    h0l = eyes [1][3]\n",
    "    \n",
    "else:\n",
    "    x0l = eyes [0][0]\n",
    "    y0l = eyes [0][1]\n",
    "    w0l = eyes [0][2]\n",
    "    h0l = eyes [0][3]\n",
    "    \n",
    "    x0r = eyes [1][0]\n",
    "    y0r = eyes [1][1]\n",
    "    w0r = eyes [1][2]\n",
    "    h0r = eyes [1][3]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale factor is calculatet and initialized counter and re-loaded the file video to allow to analyze from first frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale_f = int(0.25*(w0r+w0l)*K)\n",
    "\n",
    "video_capture = cv2.VideoCapture(video_file)\n",
    "count = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the foundamental core of the algorithm. While video file contains frames, each image is loaded, analized and the output video is created, adding output frame for each iteration. Finally video writer is release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while(video_capture.isOpened()):\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    if ret:\n",
    "        eyes=eyeCascade.detectMultiScale(frame, scaleFactor=sc_fct, minNeighbors=min_neigh, minSize=min_eye, maxSize=max_eye)\n",
    "\n",
    "        rights, lefts = check_eyes(eyes, x0r, y0r, x0l, y0l)\n",
    "\n",
    "        if len(rights) != 0:                             #right eye\n",
    "            xr, yr, wr, hr = correct_eye(rights, x0r)\n",
    "            roi_right = frame[yr:yr+hr , xr:xr+wr]\n",
    "\n",
    "            center_r, radius_r = findpupil(roi_right, xr, yr, wr)\n",
    "            if radius_r:\n",
    "                CENTERS_RIGHTS.append(center_r)\n",
    "                DIAMS_RIGHTS.append(2*K*radius_r)\n",
    "                r_check.append(True)\n",
    "\n",
    "            else:\n",
    "                CENTERS_RIGHTS.append(CENTERS_RIGHTS[count-1])\n",
    "                DIAMS_RIGHTS.append(DIAMS_RIGHTS[count-1])\n",
    "                r_check.append(False)\n",
    "        else:\n",
    "            CENTERS_RIGHTS.append(CENTERS_RIGHTS[count-1])\n",
    "            DIAMS_RIGHTS.append(DIAMS_RIGHTS[count-1])\n",
    "            r_check.append(False)\n",
    "\n",
    "        if len(lefts) != 0:                              #left eye\n",
    "            xl, yl, wl, hl = correct_eye(lefts, x0l)\n",
    "            roi_left = frame[yl:yl+hl , xl:xl+wl]\n",
    "\n",
    "            center_l, radius_l = findpupil(roi_left, xl, yl, wl)\n",
    "            if radius_l:\n",
    "                CENTERS_LEFTS.append(center_l)\n",
    "                DIAMS_LEFTS.append(2*K*radius_l)\n",
    "                l_check.append(True)\n",
    "\n",
    "            else:\n",
    "                CENTERS_LEFTS.append(CENTERS_LEFTS[count-1])\n",
    "                DIAMS_LEFTS.append(DIAMS_LEFTS[count-1])\n",
    "                l_check.append(False)\n",
    "        else:\n",
    "            CENTERS_LEFTS.append(CENTERS_LEFTS[count-1])\n",
    "            DIAMS_LEFTS.append(DIAMS_LEFTS[count-1])\n",
    "            l_check.append(False)\n",
    "            \n",
    "        # output management\n",
    "        rubber(bground)\n",
    "        \n",
    "        roi_r = frame[y0r-bound: y0r+h0r+bound , x0r-bound:x0r+w0r+bound]\n",
    "        roi_l = frame[y0l-bound:y0l+h0l+bound , x0l-bound:x0l+w0l+bound]\n",
    "        res_right = cv2.resize(roi_r,None, fx=res_fac, fy=res_fac, interpolation = cv2.INTER_LINEAR) #resized eyes\n",
    "        res_left = cv2.resize(roi_l, None,fx=res_fac, fy=res_fac, interpolation = cv2.INTER_LINEAR)\n",
    "        \n",
    "        cv2.circle(frame,CENTERS_RIGHTS[count],int(0.5*DIAMS_RIGHTS[count]/K),(0,0,255),1)\n",
    "        cv2.circle(frame,CENTERS_LEFTS[count],int(0.5*DIAMS_LEFTS[count]/K),(0,0,255),1)\n",
    "        \n",
    "        pos_r = int(bgW - res_fac*(w0r + 2*bound))                 #drawing resized eyes\n",
    "        pos_vl = int(bgH - res_fac*(h0l + 2*bound))\n",
    "        pos_vr = int(bgH - res_fac*(h0r + 2*bound))\n",
    "        draw(bground, frame, 0, 0)\n",
    "        draw(bground, res_left, pos_vl, 0)\n",
    "        draw(bground, res_right, pos_vr, pos_r)\n",
    "        \n",
    "        write_img(bground, count, DIAMS_RIGHTS[count], DIAMS_LEFTS[count], scale_f)\n",
    "        \n",
    "        count += 1\n",
    "        if not(count%60):                   #update eye positions\n",
    "            x0r = xr\n",
    "            y0r = yr\n",
    "\n",
    "            x0l = xl\n",
    "            y0l = yl   \n",
    "        out.write(bground)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "del DIAMS_LEFTS[0]\n",
    "del DIAMS_RIGHTS[0]\n",
    "\n",
    "video_capture.release()\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
