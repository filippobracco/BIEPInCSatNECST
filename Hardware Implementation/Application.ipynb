{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Biepincs application\n",
    "Acceleration of OpenCV application integrating an hardware accelerator loaded on FPGA. Application analizes a video file containing a stimulation test of a injured patient, taken with an infrared camera. Kinematic and geometric parameters of pupils are measured and saved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Overlay as to be iported and loaded on device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "ol = Overlay(\"biepincs.bit\")\n",
    "ol.download()\n",
    "ol.bitstream.timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Import libraries to be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import threading\n",
    "from pynq.drivers import DMA\n",
    "import time\n",
    "from cffi import FFI\n",
    "ffi = FFI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Constant definition:\n",
    "W and halfWidth are the dimension and the half-dimension of ROI image, CH is the number of channel of imageand TH is the value applied within the threshold filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W = 50\n",
    "halfWidth = 0.5*W\n",
    "CH = 3\n",
    "TH = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### DMA inizialization: \n",
    "Two differents DMAs are instantiated at the same address, one for reading and one for writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dmaOut = DMA(0x40400000,1)\n",
    "dmaIn = DMA(0x40400000,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Two buffers are created containing data to be tranfered to PL (dmaIn) and output results (dmaOut)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dmaIn.create_buf(W*W*CH+1)\n",
    "dmaOut.create_buf(W*W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Pointers to buffers are taken in order to allow to write and read data. Another buffer is allocated (at the same position of the DMA's out one) to allow to read data using numpy.frombuffer function.\n",
    "First value of input buffer is set with threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pointIn = ffi.cast(\"uint8_t *\", dmaIn.get_buf())\n",
    "pointOut = ffi.cast(\"uint8_t *\", dmaOut.get_buf())\n",
    "c_buffer = ffi.buffer(pointOut, W*W)\n",
    "pointIn[0] = TH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Setting parameters for video analysis :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Path to source folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "source_folder = \"./Assets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Parameters for Cascadeclassifier function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sc_fct = 1.3              \n",
    "min_neigh = 3            \n",
    "min_eye = (40, 40)\n",
    "max_eye = (60, 60)\n",
    "eyes = []\n",
    "eyeCascade=cv2.CascadeClassifier(source_folder + \"haarcascade_eye.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Inizialize lists containing values calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "CENTERS_RIGHTS = [(0,0)]\n",
    "DIAMS_RIGHTS = [0]\n",
    "CENTERS_LEFTS = [(0,0)]\n",
    "DIAMS_LEFTS = [0]\n",
    "r_check = []\n",
    "l_check = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Loading video file to be analized and extract main features on dimension and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "video_file = source_folder + \"dinamic_stimulation.mp4\"\n",
    "#video_file = source_folder + \"light_stimulation.mp4\"\n",
    "video_capture = cv2.VideoCapture(video_file)\n",
    "video_width = int(video_capture.get(3)) \n",
    "video_height = int(video_capture.get(4))\n",
    "frps = int(video_capture.get(5))\n",
    "frames = int(video_capture.get(7))\n",
    "Tc = 1/frps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "MAX_DISTANCE is the maximum allowed variation of distance (pixel) between centers of eyes, used as a threshold to classify if a pupil is lost. \n",
    "MAX_PUPIL_LOST is the maximum consecutive frames without a pupil, befor calling tha Cascadeclassifier.\n",
    "MIN_RAD is the minimum allowed value of pupil radius.\n",
    "Other variables halp to manage calls of Cascadeclassifier function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAX_DISTANCE = 40\n",
    "MAX_PUPIL_LOST = 10\n",
    "MIN_RAD = W/20\n",
    "rightEyeLost = False\n",
    "leftEyeLost = False\n",
    "LeftPupilCounter = 0\n",
    "RightPupilCounter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Defining a conversion factor between a space Unit of Measure (uom) and pixel. It dependes on video acquisition setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "K = 0.24 #from pixel to mm\n",
    "uom = 'mm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Defining functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This function takes as input a list of eyes and returns the biggest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def max_area_eye(eye_list):\n",
    "    eye = []\n",
    "    MArea = 0;\n",
    "    for ey in eye_list:\n",
    "        if ey[2]*ey[3] > MArea:\n",
    "            eye = ey\n",
    "            \n",
    "    return eye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Function calculates countours of an image, selects the biggest and approximates it as a circle. Output parameters are center, as a list of integer x and y values, and radius. If there are no contours, function returns None as center and -1 value for radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def findpupil(roi):\n",
    "    \n",
    "    _, contours,_ = cv2.findContours(roi,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    lengthCnt = len(contours) \n",
    "    \n",
    "    if lengthCnt == 0:\n",
    "        return None, -1\n",
    "    \n",
    "    if lengthCnt >=2:\n",
    "        maxArea = 0;\n",
    "        MAindex = 0;\n",
    "        cIndex = 0;\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area < maxArea:\n",
    "                maxArea = area\n",
    "                MAindex = cIndex\n",
    "            cIndex = cIndex+1\n",
    "        (cen, rad) = cv2.minEnclosingCircle(contours[MAindex]);\n",
    "        cx, cy = cen;\n",
    "        return [int(cx), int(cy)], rad\n",
    "    else:\n",
    "        (cen, rad) = cv2.minEnclosingCircle(contours[0]);\n",
    "        cx, cy = cen;\n",
    "        return [int(cx), int(cy)], rad\n",
    "    return None, -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Function loads images from video file as a buffer of two frames. It is executed with a thread.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def loadFrames(eFrame, eMain):\n",
    "    tm = []\n",
    "    global frame1\n",
    "    global frame2\n",
    "    global ret\n",
    "    while ret:\n",
    "        ret, frame1 = video_capture.read()\n",
    "        eFrame.set()\n",
    "        eMain.wait()\n",
    "        eMain.clear()\n",
    "        \n",
    "        ret, frame2 = video_capture.read()\n",
    "        eFrame.set()\n",
    "        eMain.wait()\n",
    "        eMain.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## First part of application:\n",
    "This part is non iterative. Finds the firsts two eyes using Cascadeclassifier function and saves their positions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "while len(eyes) != 2:\n",
    "    ret, frame = video_capture.read()\n",
    "    eyes=eyeCascade.detectMultiScale(frame, scaleFactor=sc_fct, minNeighbors=min_neigh, minSize=min_eye, maxSize=max_eye)\n",
    "    \n",
    "if eyes[0][0] > eyes[1][0]:\n",
    "    \n",
    "    right_pup_x = eyes [0][0]\n",
    "    right_pup_y = eyes [0][1]\n",
    "    \n",
    "    left_pup_x = eyes [1][0]\n",
    "    left_pup_y = eyes [1][1]\n",
    "    \n",
    "else:\n",
    "    left_pup_x = eyes [0][0]\n",
    "    left_pup_y = eyes [0][1]\n",
    "    \n",
    "    right_pup_x = eyes [1][0]\n",
    "    right_pup_y = eyes [1][1]\n",
    "\n",
    "radius_l = 0;\n",
    "radius_r = 0;\n",
    "distancePups = np.sqrt((left_pup_x - right_pup_x)**2 + (left_pup_y - right_pup_y)**2)\n",
    "video_capture = cv2.VideoCapture(video_file)\n",
    "count = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Main part of application \n",
    "At the beginning a thread that is in charge of loading all frames, one by one, is created and started. \n",
    "In the iterative part, if pupil is lost in the previous frame eye is searched. Then iterative part of analysis is started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(video_file)\n",
    "ret = True\n",
    "eFrame = threading.Event()\n",
    "eMain = threading.Event()\n",
    "frame1 = True\n",
    "frame2 = True\n",
    "thread = threading.Thread(target=loadFrames, args=(eFrame, eMain))\n",
    "thread.start()\n",
    "\n",
    "while(True):\n",
    "    \n",
    "    eFrame.wait()\n",
    "    \n",
    "    if ret:\n",
    "        \n",
    "        #search right eye if lost\n",
    "        if (RightPupilCounter > MAX_PUPIL_LOST or rightEyeLost):\n",
    "            eyes=eyeCascade.detectMultiScale(frame1[:, int(0.5*video_width):video_width], scaleFactor=sc_fct, minNeighbors=min_neigh, minSize=min_eye, maxSize=max_eye)\n",
    "            if len(eyes) != 0: \n",
    "                r = max_area_eye(eyes)\n",
    "                r[0] = r[0] + int(0.5*video_width);\n",
    "                if r[2] > 0:\n",
    "                    rightEyeLost = False\n",
    "                    right_pup_x = r[0]\n",
    "                    right_pup_y = r[1]\n",
    "        #search left eye if lost\n",
    "        if (LeftPupilCounter > MAX_PUPIL_LOST or leftEyeLost):\n",
    "            eyes=eyeCascade.detectMultiScale(frame1[:, 0:int(0.5*video_width)], scaleFactor=sc_fct, minNeighbors=min_neigh, minSize=min_eye, maxSize=max_eye)\n",
    "            if len(eyes) != 0: \n",
    "                l = max_area_eye(eyes)\n",
    "                if l[2] > 0:\n",
    "                    leftEyeLost = False\n",
    "                    left_pup_x = l[0]\n",
    "                    left_pup_y = l[1]\n",
    "                    \n",
    "        #roi copy of the rigth eye\n",
    "        roiRightEye = frame1[int(right_pup_y): int(right_pup_y+W), int(right_pup_x):int(right_pup_x+W)].copy()\n",
    "        #pointer to image (roi)\n",
    "        pointerToRoiRightEye = ffi.cast(\"uint8_t *\", ffi.from_buffer(roiRightEye))\n",
    "        #transfer image data to buffer\n",
    "        ffi.memmove(pointIn+1, pointerToRoiRightEye, W*W*CH) \n",
    "        \n",
    "        #DMA tranfer\n",
    "        dmaOut.transfer(W*W, 1)\n",
    "        dmaIn.transfer(W*W*CH, 0)\n",
    "        \n",
    "        #roi copy of left eye\n",
    "        roiLeftEye = frame1[int(left_pup_y): int(left_pup_y+W), int(left_pup_x):int(left_pup_x+W)].copy()\n",
    "        #pointer to image (roi)\n",
    "        pointerToRoiLeftEye = ffi.cast(\"uint8_t *\", ffi.from_buffer(roiLeftEye))\n",
    "        #transfer image data to buffer\n",
    "        ffi.memmove(pointIn+1, pointerToRoiLeftEye, W*W*CH) \n",
    "        \n",
    "        #get image analysed from buffer\n",
    "        resultRight = np.frombuffer(c_buffer, dtype=np.uint8)\n",
    "        resultRight = resultRight.reshape(W,W)\n",
    "        threshRight = resultRight.copy()\n",
    "        \n",
    "        #DMA tranfer\n",
    "        dmaOut.transfer(W*W, 1)\n",
    "        dmaIn.transfer(W*W*CH, 0)\n",
    "    \n",
    "        #get center and radius\n",
    "        center_r, radius_r = findpupil(threshRight)\n",
    "    \n",
    "        #get image analysed from buffer\n",
    "        resultLeft = np.frombuffer(c_buffer, dtype=np.uint8)\n",
    "        resultLeft = resultLeft.reshape(W,W)\n",
    "        threshLeft = resultLeft.copy()\n",
    "        \n",
    "        #get center and radius\n",
    "        center_l, radius_l = findpupil(threshLeft)\n",
    "        \n",
    "        if radius_r > MIN_RAD:\n",
    "            if RightPupilCounter != 0:\n",
    "                RightPupilCounter = 0 \n",
    "            #update x and y position of ROI centered on the new pupil center\n",
    "            right_pup_x = center_r[0] - halfWidth + right_pup_x\n",
    "            right_pup_y = center_r[1] - halfWidth + right_pup_y\n",
    "            #store new center and diameter values\n",
    "            CENTERS_RIGHTS.append(center_r)\n",
    "            DIAMS_RIGHTS.append(2*K*radius_r)\n",
    "            r_check.append(True)\n",
    "        elif count != 0: #if pupil is not found, we store the previous valid value\n",
    "            RightPupilCounter = RightPupilCounter +1\n",
    "            CENTERS_RIGHTS.append(CENTERS_RIGHTS[count-1])\n",
    "            DIAMS_RIGHTS.append(DIAMS_RIGHTS[count-1])\n",
    "            r_check.append(False)\n",
    "            \n",
    "            \n",
    "        if radius_l > MIN_RAD:\n",
    "            if LeftPupilCounter != 0:\n",
    "                LeftPupilCounter = 0 \n",
    "            #update x and y position of ROI centered on the new pupil center\n",
    "            left_pup_x = center_l[0] - halfWidth + left_pup_x\n",
    "            left_pup_y = center_l[1] - halfWidth + left_pup_y\n",
    "            #store new center and diameter values\n",
    "            CENTERS_LEFTS.append(center_l)\n",
    "            DIAMS_LEFTS.append(2*K*radius_l)\n",
    "            l_check.append(True)\n",
    "        elif count != 0: #if pupil is not found, we store the previous valid value\n",
    "            LeftPupilCounter = LeftPupilCounter +1\n",
    "            CENTERS_LEFTS.append(CENTERS_LEFTS[count-1])\n",
    "            DIAMS_LEFTS.append(DIAMS_LEFTS[count-1])\n",
    "            l_check.append(False)\n",
    "        \n",
    "        #Calculate the distance between centers of eyes\n",
    "        distance = np.sqrt((left_pup_x - right_pup_x)**2 + (left_pup_y - right_pup_y)**2) \n",
    "        \n",
    "        #apply a classification based on the difference of distance between current value and a weighted value of previous frames right eye\n",
    "        if (abs(distance - distancePups) > MAX_DISTANCE and count !=0):\n",
    "            dist_lefts = np.sqrt((CENTERS_LEFTS[count-1][0] - CENTERS_LEFTS[count-2][0])**2 + (CENTERS_LEFTS[count-1][1] - CENTERS_LEFTS[count-2][1])**2)\n",
    "            dist_rights = np.sqrt((CENTERS_RIGHTS[count-1][0] - CENTERS_RIGHTS[count-2][0])**2 + (CENTERS_RIGHTS[count-1][1] - CENTERS_RIGHTS[count-2][1])**2)\n",
    "            if dist_lefts > dist_rights:\n",
    "                leftEyeLost = True; \n",
    "                DIAMS_LEFTS[count] = DIAMS_LEFTS[count-1];\n",
    "                CENTERS_LEFTS[count] = CENTERS_LEFTS[count-1];\n",
    "            else:\n",
    "                rightEyeLost = True;\n",
    "                DIAMS_RIGHTS[count] = DIAMS_RIGHTS[count-1];\n",
    "                CENTERS_RIGHTS[count] = CENTERS_RIGHTS[count-1]; \n",
    "        \n",
    "        #apply a classification based on the difference of distance between current value and a weighted value of previous frames for left eye\n",
    "        if (abs(distance - distancePups) > MAX_DISTANCE and count !=0):\n",
    "            dist_lefts = np.sqrt((CENTERS_LEFTS[count-1][0] - CENTERS_LEFTS[count-2][0])**2 + (CENTERS_LEFTS[count-1][1] - CENTERS_LEFTS[count-2][1])**2)\n",
    "            dist_rights = np.sqrt((CENTERS_RIGHTS[count-1][0] - CENTERS_RIGHTS[count-2][0])**2 + (CENTERS_RIGHTS[count-1][1] - CENTERS_RIGHTS[count-2][1])**2)\n",
    "            if dist_lefts > dist_rights:\n",
    "                leftEyeLost = True;\n",
    "                l_check[count-1] = False;\n",
    "                DIAMS_LEFTS[count] = DIAMS_LEFTS[count-1];\n",
    "                CENTERS_LEFTS[count] = CENTERS_LEFTS[count-1];\n",
    "            else:\n",
    "                rightEyeLost = True;\n",
    "                r_check[count-1] = False;\n",
    "                DIAMS_RIGHTS[count] = DIAMS_RIGHTS[count-1];\n",
    "                CENTERS_RIGHTS[count] = CENTERS_RIGHTS[count-1];\n",
    "        \n",
    "        #update the weighted mean of distance        \n",
    "        distancePups = (count*distancePups + distance)/(count+1);\n",
    "        \n",
    "        eFrame.clear()\n",
    "        eMain.set()\n",
    "        eFrame.wait()\n",
    "    else:\n",
    "        break\n",
    "    count += 1    \n",
    "    \n",
    "    #we applied the same procedure to the second frame loaded of the buffer\n",
    "    \n",
    "    if ret:\n",
    "        #search right eye if lost\n",
    "        if (RightPupilCounter > MAX_PUPIL_LOST or rightEyeLost):\n",
    "            eyes=eyeCascade.detectMultiScale(frame2[:, int(0.5*video_width):video_width], scaleFactor=sc_fct, minNeighbors=min_neigh, minSize=min_eye, maxSize=max_eye)\n",
    "            if len(eyes) != 0: \n",
    "                r = max_area_eye(eyes)\n",
    "                r[0] = r[0] + int(0.5*video_width);\n",
    "                if r[2] > 0:\n",
    "                    rightEyeLost = False\n",
    "                    right_pup_x = r[0]\n",
    "                    right_pup_y = r[1]\n",
    "        \n",
    "        #search left eye if lost\n",
    "        if (LeftPupilCounter > MAX_PUPIL_LOST or leftEyeLost):\n",
    "            eyes=eyeCascade.detectMultiScale(frame2[:, 0:int(0.5*video_width)], scaleFactor=sc_fct, minNeighbors=min_neigh, minSize=min_eye, maxSize=max_eye)\n",
    "            if len(eyes) != 0: \n",
    "                l = max_area_eye(eyes)\n",
    "                if l[2] > 0:\n",
    "                    leftEyeLost = False\n",
    "                    left_pup_x = l[0]\n",
    "                    left_pup_y = l[1]\n",
    "        \n",
    "        #roi copy of the rigth eye\n",
    "        roiRightEye = frame2[int(right_pup_y): int(right_pup_y+W), int(right_pup_x):int(right_pup_x+W)].copy()\n",
    "        #pointer to image (roi)\n",
    "        pointerToRoiRightEye = ffi.cast(\"uint8_t *\", ffi.from_buffer(roiRightEye))\n",
    "        #transfer image data to buffer\n",
    "        ffi.memmove(pointIn+1, pointerToRoiRightEye, W*W*CH) \n",
    "\n",
    "        #dma tranfer\n",
    "        dmaOut.transfer(W*W, 1)\n",
    "        dmaIn.transfer(W*W*CH, 0)\n",
    "        \n",
    "        #roi copy of left eye\n",
    "        roiLeftEye = frame2[int(left_pup_y): int(left_pup_y+W), int(left_pup_x):int(left_pup_x+W)].copy()\n",
    "        #pointer to image (roi)\n",
    "        pointerToRoiLeftEye = ffi.cast(\"uint8_t *\", ffi.from_buffer(roiLeftEye))\n",
    "        #transfer image data to buffer\n",
    "        ffi.memmove(pointIn+1, pointerToRoiLeftEye, W*W*CH) \n",
    "        \n",
    "        #get image analysed from buffer\n",
    "        resultRight = np.frombuffer(c_buffer, dtype=np.uint8)\n",
    "        resultRight = resultRight.reshape(W,W)\n",
    "        threshRight = resultRight.copy()\n",
    "        \n",
    "         #dma tranfer\n",
    "        dmaOut.transfer(W*W, 1)\n",
    "        dmaIn.transfer(W*W*CH, 0)\n",
    "        \n",
    "        #get center and radius\n",
    "        center_r, radius_r = findpupil(threshRight)\n",
    "        \n",
    "        #get image analysed from buffer\n",
    "        resultLeft = np.frombuffer(c_buffer, dtype=np.uint8)\n",
    "        resultLeft = resultLeft.reshape(W,W)\n",
    "        threshLeft = resultLeft.copy()\n",
    "        \n",
    "        #get center and radius\n",
    "        center_l, radius_l = findpupil(threshLeft)\n",
    "        \n",
    "        if radius_r > MIN_RAD:\n",
    "            if RightPupilCounter != 0:\n",
    "                RightPupilCounter = 0 \n",
    "            #update x and y position of ROI centered on the new pupil center\n",
    "            right_pup_x = center_r[0] - halfWidth + right_pup_x\n",
    "            right_pup_y = center_r[1] - halfWidth + right_pup_y\n",
    "            #store new center and diameter values\n",
    "            CENTERS_RIGHTS.append(center_r)\n",
    "            DIAMS_RIGHTS.append(2*K*radius_r)\n",
    "            r_check.append(True)\n",
    "        elif count != 0: #if pupil is not found, we store the previous valid value\n",
    "            RightPupilCounter = RightPupilCounter +1\n",
    "            CENTERS_RIGHTS.append(CENTERS_RIGHTS[count-1])\n",
    "            DIAMS_RIGHTS.append(DIAMS_RIGHTS[count-1])\n",
    "            r_check.append(False)\n",
    "            \n",
    "        if radius_l > MIN_RAD:\n",
    "            if LeftPupilCounter != 0:\n",
    "                LeftPupilCounter = 0 \n",
    "            #update x and y position of ROI centered on the new pupil center\n",
    "            left_pup_x = center_l[0] - halfWidth + left_pup_x\n",
    "            left_pup_y = center_l[1] - halfWidth + left_pup_y\n",
    "            #store new center and diameter values\n",
    "            CENTERS_LEFTS.append(center_l)\n",
    "            DIAMS_LEFTS.append(2*K*radius_l)\n",
    "            l_check.append(True)\n",
    "        elif count != 0: #if pupil is not found, we store the previous valid value\n",
    "            LeftPupilCounter = LeftPupilCounter +1\n",
    "            CENTERS_LEFTS.append(CENTERS_LEFTS[count-1])\n",
    "            DIAMS_LEFTS.append(DIAMS_LEFTS[count-1])\n",
    "            l_check.append(False)\n",
    "            \n",
    "        #Calculate the distance between centers of eyes    \n",
    "        distance = np.sqrt((left_pup_x - right_pup_x)**2 + (left_pup_y - right_pup_y)**2) \n",
    "        \n",
    "        #apply a classification based on the difference of distance between current value and a weighted value of previous frames right eye\n",
    "        if (abs(distance - distancePups) > MAX_DISTANCE and count !=0):\n",
    "            dist_lefts = np.sqrt((CENTERS_LEFTS[count-1][0] - CENTERS_LEFTS[count-2][0])**2 + (CENTERS_LEFTS[count-1][1] - CENTERS_LEFTS[count-2][1])**2)\n",
    "            dist_rights = np.sqrt((CENTERS_RIGHTS[count-1][0] - CENTERS_RIGHTS[count-2][0])**2 + (CENTERS_RIGHTS[count-1][1] - CENTERS_RIGHTS[count-2][1])**2)\n",
    "            if dist_lefts > dist_rights:\n",
    "                leftEyeLost = True;\n",
    "                DIAMS_LEFTS[count] = DIAMS_LEFTS[count-1];\n",
    "                CENTERS_LEFTS[count] = CENTERS_LEFTS[count-1];\n",
    "            else:\n",
    "                rightEyeLost = True;\n",
    "                DIAMS_RIGHTS[count] = DIAMS_RIGHTS[count-1];\n",
    "                CENTERS_RIGHTS[count] = CENTERS_RIGHTS[count-1]; \n",
    "        \n",
    "        #apply a classification based on the difference of distance between current value and a weighted value of previous frames left eye\n",
    "        if (abs(distance - distancePups) > MAX_DISTANCE and count !=0):\n",
    "            dist_lefts = np.sqrt((CENTERS_LEFTS[count-1][0] - CENTERS_LEFTS[count-2][0])**2 + (CENTERS_LEFTS[count-1][1] - CENTERS_LEFTS[count-2][1])**2)\n",
    "            dist_rights = np.sqrt((CENTERS_RIGHTS[count-1][0] - CENTERS_RIGHTS[count-2][0])**2 + (CENTERS_RIGHTS[count-1][1] - CENTERS_RIGHTS[count-2][1])**2)\n",
    "            if dist_lefts > dist_rights:\n",
    "                leftEyeLost = True;\n",
    "                DIAMS_LEFTS[count] = DIAMS_LEFTS[count-1];\n",
    "                CENTERS_LEFTS[count] = CENTERS_LEFTS[count-1];\n",
    "            else:\n",
    "                rightEyeLost = True;\n",
    "                DIAMS_RIGHTS[count] = DIAMS_RIGHTS[count-1];\n",
    "                CENTERS_RIGHTS[count] = CENTERS_RIGHTS[count-1];\n",
    "        #update the weighted mean of distance          \n",
    "        distancePups = (count*distancePups + distance)/(count+1);\n",
    "        \n",
    "        eFrame.clear()\n",
    "        eMain.set()\n",
    "        eFrame.wait()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "    count += 1\n",
    "        \n",
    "del DIAMS_LEFTS[0]\n",
    "del DIAMS_RIGHTS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Store values in a file:\n",
    "File containing values computed is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "outputFile = open('Output.txt','w')\n",
    "for i in range(count):\n",
    "    outputFile.write(str(CENTERS_RIGHTS[i][0])+' '+str(CENTERS_RIGHTS[i][1])+' '+str(DIAMS_RIGHTS[i])+' '+str(CENTERS_LEFTS[i][0])+' '+str(CENTERS_LEFTS[i][1])+' '+str(DIAMS_LEFTS[i])+'\\n')\n",
    "outputFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
